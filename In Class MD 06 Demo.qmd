---
title: "MD06 Demo, Part I"
format: html
editor: visual
embed-resources: true
---

Load packages and set theme.

```{r}
#| message: false
library(tidyverse)
library(moderndive)
library(patchwork)
theme_set(theme_light())
```

Let's look at the MD evaluations data.

```{r}
data(evals)
glimpse(evals)
```

We are going to ask whether the "beauty" of an instructor predicts their teaching evaluations.

```{r}
d <- evals |>
  rename(bty = bty_avg,    # just shorter to type
         sex = gender)     # actually what they have

glimpse(d)
```

Let's look at the first few cases.

```{r}
head(d)
```

Here's the regression from last week.

```{r}
mod1 <- lm(score ~ bty,
           data = d)

get_regression_table(mod1)
```

**Note**: When beauty (x) is 0, we expect a person to get a teaching evaluation of 3.88. This has no substantive value because beauty will never be 0. However, it is worth noting that this is what the numerical values indicate. Note also that every time we move 1 beauty point to the right, we can expect the teaching evaluation to go up by .067.

Let's look at the predictions and residuals.

```{r}
mod1_preds <- get_regression_points(mod1) #regression model 1 predictions
                                          #using get_regression_points function from modern dive

head(mod1_preds)
#residual = difference between what we saw and what we expected to see
```

Here's the regression line (blue).

```{r,echo=FALSE}
ggplot(d,
       aes(x = bty,
           y = score)) +
  geom_jitter(alpha = .3) +
  geom_smooth(method = "lm", 
              se = FALSE) + 
  labs(x = "Beauty",
       y = "Evaluation",
       title = "Simple regression results")
```

Here are the residuals.

```{r,echo=FALSE}
ggplot(mod1_preds,
       aes(x = bty,
           y = residual)) +
  geom_jitter(alpha = .3) +
  geom_hline(yintercept = 0,
             color = "blue") +
  labs(x = "Beauty",
       y = "Residual",
       title = "Simple regression residuals")
```

**Note**: The y-axis is no longer score; the y-axis is now our guess. Moreover, the residual plot can reveal the wrong model type (i.e., data follows a parabola but you used `lm`).

One way to quantify how well a predictor predicts the outcome is to use the **variance**. We've seen this already but let's review. Here's the formula. $\bar{y}$ is the mean of $y$.

$$
V(y) = \frac{1}{n-1}\sum_{i=1}^{n}(y_i - \bar{y})^2
$$

**Note**: Equation above is basically the average squared distance from the observation to the mean.

Since our outcome is evaluation score, we can just do that.

```{r}
var_y <- d |> 
  pull(score) |> 
  var()

var_y
```

**Note**: We are only using the scores here; we are not using beauty at all. We are looking to understand the variance that exists in the first place among course evaluations. ("some do, some don't")

This is equivalent to the variance of the "residuals" when we just guess the mean value for every person!

```{r, echo=FALSE}
ggplot(d,
       aes(x = bty,
           y = score)) +
  geom_jitter(alpha = .3) +
  geom_hline(yintercept = mean(d$score),
             color = "blue") +
  labs(x = "Beauty",
       y = "Evaluation",
       title = "Guessing the mean for everyone")
```

**Note**: Can guess the average for everyone. OR, if I knew the beauty score, maybe I could improve my guess of evaluations.

Adding `beauty` as a predictor improves our guess.

```{r, echo=FALSE}
ggplot(d,
       aes(x = bty,
           y = score)) +
  geom_jitter(alpha = .3) +
  geom_hline(yintercept = mean(d$score),
             color = "blue") +
  geom_smooth(method = "lm",
              se = FALSE,
              color = "red",
              linetype = "dashed") +
  labs(x = "Beauty",
       y = "Evaluation",
       title = "Mean vs. regression line")
```

**Note**: In this dataset, using other information will always improve your guess in the sample. However, it is also kind of cheating, because we are using our sample to predict our sample.

Now let's see what the spread looks like if we look at the residuals from the regression line.

```{r}
var_yhat1 <- mod1_preds |> 
  pull(residual) |> 
  var()

var_yhat1
```

**Note**: variance went down a little when account for beauty (from .29 to .28). Also, (.29-.28)/.29 = 3.5%, meaning beauty explains 3.5% of the variance. Takeaway: we make better guesses when we use other information. Also, even small values can be significant (these are called "marginal gains" in the sports realms).

If we take the ratio of these and subtract it from one, that gives us the $R^2$ or "proportion of variance explained" by beauty scores.

```{r}
1 - (var_yhat1 / var_y)
```

It looks like "beauty" can account for about `r round((1 - (var_yhat1 / var_y)) * 100, 1)` percent of the variance in the evaluation scores.

In other words, if we try to guess instructors' evaluation scores, our guesses will be `r round((1 - (var_yhat1 / var_y)) * 100, 1)` percent *less wrong* on average if we know the instructor's beauty rating.

We can get this from `broom::glance()` or `moderndive::get_regression_summaries()` without doing it manually. The latter will be a more curated list of things you'll need for this course.

```{r}
broom::glance(mod1)
moderndive::get_regression_summaries(mod1)
```

**Note**: If we want to know the maximum difference beauty could make between the prettiest and ugliest instructor, we could run: `max(d$bty).067 - min(d$bty).067` in the console (= .435). In other words, the model thinks the biggest difference that beauty could make is .435 points on a 10-point scale.

## Individual Practice

I am going to follow the same workflow as above, this time using the variable `age` instead of `beauty`.

I am going to begin by running a regression.

```{r}
mod1b <- lm(score ~ age,
           data = d)

get_regression_table(mod1b)
```

When age (x) is 0, we expect a person to get a teaching evaluation of 4.462. This has no substantive value because age will never be 0. Note also that every time someones age increases by one year, we can expect the teaching evaluation to go down by .006.

Next, I am going to look at the predictions and residuals.

```{r}
mod1b_preds <- get_regression_points(mod1b) 
head(mod1b_preds)
```

The above tibble shows the values for the actual scores (`score`) and the scores we would expect/guess (`score_hat`) to see.

Here's the regression line (blue).

```{r,echo=FALSE}
ggplot(d,
       aes(x = age,
           y = score)) +
  geom_jitter(alpha = .3) +
  geom_smooth(method = "lm", 
              se = FALSE) + 
  labs(x = "Age",
       y = "Evaluation",
       title = "Simple regression results")
```

Here are the residuals.

```{r,echo=FALSE}
ggplot(mod1b_preds,
       aes(x = age,
           y = residual)) +
  geom_jitter(alpha = .3) +
  geom_hline(yintercept = 0,
             color = "blue") +
  labs(x = "Age",
       y = "Residual",
       title = "Simple regression residuals")
```

Earlier, we calculated the variance of our outcome - the evaluation score (`var_y`). I am going to show the plot when when we add `age` as a predictor and improve our guess.

```{r, echo=FALSE}
ggplot(d,
       aes(x = age,
           y = score)) +
  geom_jitter(alpha = .3) +
  geom_hline(yintercept = mean(d$score),
             color = "blue") +
  geom_smooth(method = "lm",
              se = FALSE,
              color = "red",
              linetype = "dashed") +
  labs(x = "Age",
       y = "Evaluation",
       title = "Mean vs. regression line")
```

Now I am going to see what the spread looks like if we look at the residuals from the regression line.

```{r}
var_yhat1b <- mod1b_preds |> 
  pull(residual) |> 
  var()

var_yhat1b
```

Finally, I am going to find $R^2$ or "proportion of variance explained" by age. I am going to do this both manually and using the `broom` function.

```{r}
1 - (var_yhat1b / var_y)
```

```{r}
broom::glance(mod1b)
```

## Resume here

Let's try a different predictor. Let's predict ratings with `sex`.

```{r}
mod2 <- lm(score ~ sex,
           data = d)

get_regression_table(mod2)
get_regression_summaries(mod2)
```

Looks like male instructors get slightly better evaluations but this only accounts for a tiny bit of the of the variance. Don't be confused however: small amounts of variance can be really important even if they don't tell the whole story of variability.

In general, we are not going to want to do this with different variables one by one. We want to do **multiple regression**.

```{r}
mod3 <- lm(score ~ bty + sex,
           data = d)

get_regression_table(mod3)
```

Here's what this model does.

```{r, echo=FALSE}
ggplot(d,
       aes(x = bty,
           y = score,
           group = sex,
           color = sex)) +
  geom_jitter(alpha = .3) +
  geom_parallel_slopes(se = FALSE) +  # this is a modern dive thing!
  theme(legend.position = "top")
```

Here's the formula:

$$
\widehat{score}_i = 3.75 + .074(beauty_i) + .172(male_i)
$$

We might instead prefer a model like this, which allows the relationship between beauty and evaluations to be *different* for male and female instructors.

```{r, echo=FALSE}
ggplot(d,
       aes(x = bty,
           y = score,
           group = sex,
           color = sex)) +
  geom_jitter(alpha = .3) +
  geom_smooth(method = "lm",
              se = FALSE) +
  theme(legend.position = "top")
```

Here's the syntax, results, and formula.

```{r}
mod4 <- lm(score ~ bty + sex + bty:sex,
           data = d)

get_regression_table(mod4)
```

$$
\widehat{score}_i = 3.95 + .031(beauty_i) + -.184(male_i) + .080(beauty_i \times male_i)
$$ The slope for female instructors is .031. The slope for male instructors is .031 + .080 = .111.

```{r}
get_regression_summaries(mod3) # parallel
get_regression_summaries(mod4) # interactions
```

Do you think this is an important improvement?
