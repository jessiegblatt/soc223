---
title: "Homework MD 06"
author: "Jessie Goldblatt"
embed-resources: true
format: html
editor: visual
---

## Setting Up

I am going to begin by loading the `tidyverse`, `broom`, and `moderndive` packages and setting my ggplot theme.

```{r}
#| message: false
library(tidyverse)
library(broom)
library(moderndive)
theme_set(theme_light())
```

I am now going to read in and look at data on the employment conditions of women across different occupations.

```{r}
#| message: false
# Read in the data in 
gender_employment <- read_csv("gender_employment.csv")

# Glimpse at the data 
glimpse(gender_employment)
```

Next, I am going to take a bird's eye view of women's earnings with respect to men's over time, using the code given in the instructions.

```{r}
#| warning: false
gender_employment%>% 
  ggplot(aes(x = year, y = wage_percent_of_male)) +
  geom_jitter(alpha = 0.1) + 
  geom_smooth(method = "lm") + 
  labs(title = "Women's earnings with respect to men's", 
       y = "% of Men's Income", 
       x = "Year")
```

The plot reveals that there is not a lot of fluctuation in women's earnings with respect to men's over time; the trend is mostly flat and has a slight positive slope. In the following sections, I am going to explore how this relationship varies *across* *occupations*.

## Question 1

I am going to begin by making `Management, Business, and Financial` the reference category so that my results are in comparison to this group, using the code given in the instructions.

```{r}
gender_employment <- gender_employment %>% 
  mutate(major_category = as.factor(major_category), 
         major_category = relevel(major_category, ref = "Management, Business, and Financial"))
```

Now, I am going to fit a model called `parallel_model` where `wage_percent_of_male` is the outcome variable and `year` and `major_category` are the explanatory variables.

```{r}
#Fit regression model
parallel_model <- lm(wage_percent_of_male ~ year + major_category, data = gender_employment)

#Get regression table
broom::tidy(parallel_model)
```

The results indicate that across all occupations, women make less than their male counterparts. This dataset begins in 2013, and at this time, we would expect a woman in our reference category of `management, business, and financial` to make 79% of her male counterpart's salary (-306.7 + .19(2013)). Even when looking across occupations, the highest this percentage becomes in the year 2013 is 86% for women in `computer, engineering, and science`. Critically, with each passing year, we can expect the wage percent a woman makes compared to her male counterpart to increase .19%. That is, the wage gap is shrinking over time.

The wage percentage of male income for `Sales and Office` occupations in 2015 is: -306.71 + 0.192(2015) + 3.326(1) = 83.91%.

The wage percentage of male income for `Service` occupations in 2016 is: -306.71 + 0.192(2016) + 6.0769(1) = 86.86%.

## Question 2

The model above assumes parallel trends, but this assumption may not be warranted.

To check, I am going to use the code from the introductory section but this time facet it by `major_category` so that lines vary across categories.

```{r}
#| warning: false
gender_employment%>% 
  ggplot(aes(x = year, 
             y = wage_percent_of_male, 
             group = major_category, 
             color = major_category)) +
  geom_jitter(alpha = 0.3) + 
  geom_smooth(method = "lm",
              se = FALSE) +
  labs(title = "Women's earnings with respect to men's", 
       y = "% of Men's Income", 
       x = "Year",
       group = "Major Category",
       color = "Major Category")
```

It appears that the trends are not parallel; the lines cross one another. For some major categories, the percentage women make with respect to men is largely stagnant, while for others, there is a slight increase over time. As such, the parallel trends assumption may not be warranted.

## Question 3

I am going to fit another model that includes an interaction between `major_category` and `year`. This will allow the slopes to differ across major categories. I am again going to use the `tidy()` function in the `broom` package to get the summary of the results.

```{r}
#Fit regression model
interaction_model <- lm(wage_percent_of_male ~ year * major_category, data = gender_employment)

#Get regression table
broom::tidy(interaction_model)
```

The estimate for `Computer, Engineering, and Science` for 2016 would be: -1370.47 + 0.72(2016) + 1002.853 + -0.4946(2016) = 87.15%.

Moreover, the estimate for `Service` for 2016 would be: -1370.47 + 0.72(2016) + 2137.65 + -1.058(2016) = 86.07%

These two estimates are indeed different; women in the `Service` industry made 86.07% of their male counterpart's salary in 2016, while women in the `Computer, Engineering, and Science` made 87.15% of their male counterpart's salary in 2016. That is, the wage gap in the `Computer, Engineering, and Science` industry was slightly smaller than the wage gap in the `Service` industry.

## Question 4

The reason why we might choose to build a model that assumes parallel trends, in spite of our ability to add interactions to models (i.e. to have slopes vary across categories), is based off a philosophical principle known as "Occam's Razor." That is, "all other things being equal, simpler models are to be preferred over complex ones." In other words, the more complex model is favorable only if if the additional complexity is *warranted*. Sometimes, the difference in slopes for the parallel trends and interaction models are nearly identical or do not differ by much, meaning the simpler parallel trends model is preferred.

## Question 5

I am going to build a model where `wage_percent_of_male` is the outcome variable and `year` is the explanatory variable and save it as `simple_fit`. Then, I am going to use `tidy()` to look at the model output.

```{r}
#Fit regression model
simple_fit <- lm(wage_percent_of_male ~ year, data = gender_employment)

#Get regression table
broom::tidy(simple_fit)
```

The results indicate that, overall, women make a fraction of what their male counterparts make - approximately 82% (-321.83 + .201(2013)) in the starting year for the dataset, 2013. However, with each passing year, this percentage increases, meaning that the wage gap between women and men is slowly shrinking over time.

I want to add another variable to the model called `percent_female`, which records the proportion of women in an industry. Before I build the model, I am going explore the relationship between the variables `percent_female`, `wage_percent_of_male`, and `year`. Because there are some missing values, I am going to give `cor()` the argument `use = "complete.obs"`.

```{r}
gender_employment %>% 
  select(year, wage_percent_of_male, percent_female) %>% 
  cor(use = "complete.obs")
```

As has already been uncovered, there is a slight positive correlation between `year` and `wage_percentage_of_male`. That is, over time, women's wages have become more similar to that of their male counterpart. There is a near zero correlation between `year` and `percent_female`. This suggests that the proportion of women in various industries has not really changed over time. Importantly, there is a slight positive correlation between `wage_percentage_of_male` and `percent_female`, meaning that the more women that belong to an industry, the smaller the wage gap tends to be (the higher the percentage for `wage_percentage_of_male`).

I want to know the relationship between year and the paygap **conditional** on the proportion of women who work in an occupation. I am going to build this model and save it as `multiple_fit`. Then, I am going to use `tidy()` to summarize the results.

```{r}
#Fit regression model
multiple_fit <- lm(wage_percent_of_male ~ year + percent_female, data = gender_employment)

#Get regression table
broom::tidy(multiple_fit)
```

The results indicate that, taking into account all the other explanatory variables in our model (`percent_female`), with each one year increase, there is an associated increase of, on average, 0.1968% in women's earnings with respect to men's. Additionally, taking into account all the other explanatory variables in our model (`year`), with each one unit increase in the proportion of women in an industry, there is an associated increase of, on average, 0.0425% in women's earnings with respect to men's.

Intuitively, this makes sense and is what I would have expected. It makes sense that with time, women's wages have become more comparable to that of men. It also makes sense that when there are more women in an industry, the wage gap tends to be smaller compared to if the field were more male-dominated.

## Question 6

R squared is a value that helps us assess how well the independent variable(s) predict the dependent variable in a model. As such, it is sometimes called the "coefficient of determination." R squared ranges in value from 0 to 1, where 0 indicates that none of the variance in the dependent variable is explained by the independent variable(s), while 1 means that all the variance in the dependent variable is accounted for by the independent variable(s).

Now, I am going to compare the R squared for `simple_fit` and `multiple_fit`. To do this, I am going to use `glance()` from the `broom` package.

First, I am going to run `glance()` on `simple_fit` and save the output. I am going to access the R squared value using the code given in the instructions.

```{r}
glance(simple_fit)
simple_glanced <- glance(simple_fit)
simple_glanced$r.squared
```

Next, I am going to run `glance()` on `multiple_fit` and again use the code given in the instructions to save the output and access the R squared value.

```{r}
glance(multiple_fit)
multiple_glanced <- glance(multiple_fit)
multiple_glanced$r.squared
```

The R squared value for `simple_fit` is .0005, while the R squared value for `multiple_fit` is .0129. A lot more of the variance in the wage gap is accounted for when I include both year *and* the proportion of females in an industry in my model. Specifically, 1.3% of the variance in the wage gap is accounted for; this variance is attributable to year and proportion of females in an industry.

## Question 7: A Warning Sign

R squared has one big weakness: it improves when you add any variable to your model.

To illustrate this, I am going to copy and paste the code from the instructions which creates a vector of random values the same size as the dataframe.

```{r}
random_numbers <- rnorm(n = nrow(gender_employment), 
                        mean = 0, 
                        sd = 4)
```

Now, I am going to add this column into the model, again using the code given in the instructions.

```{r}
gender_employment$random_noise <- random_numbers

# New model 
random_fit <- lm(wage_percent_of_male ~ year + percent_female + random_noise, data = gender_employment)
```

Finally, I am going to find the R squared value.

```{r}
glance(random_fit)
random_glanced <- glance(random_fit)
random_glanced$r.squared
```

The R squared value for the random model is .12989 - a value that is actually higher than either of the other two non-random models. This showcases how adding variables to the model will increase R squared, regardless of how nonsensical they are. Thus, it is super important to be intentional with the predictors one selects and ensure the sample and its predictors actually reflect what we would expect to find in the real world.
